{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18145,
     "status": "ok",
     "timestamp": 1622135885868,
     "user": {
      "displayName": "B.D P",
      "photoUrl": "",
      "userId": "15068402056370302801"
     },
     "user_tz": -120
    },
    "id": "5lpTxH419Dko",
    "outputId": "be5c5352-24bf-4e07-a248-87d628033fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zf3MG0KV8gPw",
    "outputId": "f269276e-936c-4cee-d293-4a2314f96195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 3, 224, 224, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 224, 224, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli (None, 224, 224, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli (None, 224, 224, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Functiona (None, 7, 7, 1280)   2257984     tf.__operators__.getitem[0][0]   \n",
      "                                                                 tf.__operators__.getitem_1[0][0] \n",
      "                                                                 tf.__operators__.getitem_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 128)          180480      mobilenetv2_1.00_224[0][0]       \n",
      "                                                                 mobilenetv2_1.00_224[1][0]       \n",
      "                                                                 mobilenetv2_1.00_224[2][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack (TFOpLambda)           (None, 128, 3)       0           sequential[0][0]                 \n",
      "                                                                 sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,438,464\n",
      "Trainable params: 180,480\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n",
      "# -------------------------------------------- MODEL FITTING -------------------------------------------- #\n",
      "Epoch 1/5\n",
      "930/930 [==============================] - 1608s 1s/step - loss: 0.5766 - get_accuracy: 0.6955\n",
      "Epoch 2/5\n",
      "305/930 [========>.....................] - ETA: 7:17 - loss: 0.5465 - get_accuracy: 0.7176"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# ---------------------------------------------------------------------------------------------------------------------------\n",
    "General Information:\n",
    "--------------------\n",
    "Task 4 -- Introduction to machine learning -- Taste Close?\n",
    "Authors: Dejan and Sindi\n",
    "\n",
    "General approach description:\n",
    "-----------------------------\n",
    "Use a pretrainded model of PyTorch/Tenserflow Keas. I.e. following the link: https://pytorch.org/vision/stable/models.html \n",
    "and https://www.tensorflow.org/tutorials/images/transfer_learning. This will allow to use an already good CNN model. \n",
    "With the pretrained model, we want to extract the features created by the model. The extracted features can then be used \n",
    "to train an classifier, depending on how close the data: I.e. how close the first image A is to B and C. \n",
    "\n",
    "Most of the code is based on the introduction to siamese networks: https://keras.io/examples/vision/siamese_network/\n",
    "Howeverr, need to make it more efficient as it takes too long... \n",
    "\n",
    "Important links\n",
    "---------------\n",
    "1)  Triamese Networks/ Transfer Learning:\n",
    "    https://medium.com/@crimy/one-shot-learning-siamese-networks-and-triplet-loss-with-keras-2885ed022352\n",
    "\n",
    "1)  Preparing the data:\n",
    "    https://keras.io/examples/vision/siamese_network/\n",
    "\n",
    "2)  How to work with with shuffle, repeat and batch of data sets. \n",
    "    https://stackoverflow.com/questions/53514495/what-does-batch-repeat-and-shuffle-do-with-tensorflow-dataset\n",
    "\n",
    "3)  Building image pipelines with tensorflow\n",
    "    https://cs230.stanford.edu/blog/datapipeline/\n",
    "\n",
    "4)  working with data papelines\n",
    "    https://stackoverflow.com/questions/56399919/proper-way-to-iterate-tf-data-dataset-in-session-for-2-0\n",
    "\n",
    "5)  Dissimmilarity similarity measureas \n",
    "    https://towardsdatascience.com/17-types-of-similarity-and-dissimilarity-measures-used-in-data-science-3eb914d2681\n",
    "# ---------------------------------------------------------------------------------------------------------------------------\n",
    "'''\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import resnet\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "# connected to GPU????\n",
    "# ---------------------------------------------------------------------------------------------------------------------------\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "\n",
    "img_size = (224,224)\n",
    "img_shape = img_size + (3,)\n",
    "\n",
    "\n",
    "# HELPER FUNCTIONS and STUFF\n",
    "# ---------------------------------------------------------------------------------------------------------------------------\n",
    "def preprocess_image(filename):\n",
    "    '''\n",
    "    preprocessing_image() was inspired by: https://keras.io/examples/vision/siamese_network/\n",
    "    Loades the specified file as a JPEG image, prerocess it by applying rescaling into [0, 1] from [0,255]. Converts it \n",
    "    into float32 and resizes it into image_size. (160, 160). Further data augmentation is done by flipping it ranodomly \n",
    "    either to left or right. Convert it into [0, 1] as the base model is set up with this values. \n",
    "    '''\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image_string, channels = 3)\n",
    "\n",
    "    rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = rescale(image)\n",
    "\n",
    "    image = tf.image.resize(image, img_size)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_test_image(filename):\n",
    "    '''\n",
    "    preprocessing_image was inspired by: https://keras.io/examples/vision/siamese_network/\n",
    "    Loades the specified file as a JPEG image, prerocess it by applying rescaling into [0, 1] from [0,255]. Converts it \n",
    "    into float32 and resizes it into image_size. (160, 160). Further data augmentation is done by flipping it ranodomly \n",
    "    either to left or right. \n",
    "    '''\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image_string, channels = 3)\n",
    "\n",
    "    rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = rescale(image)\n",
    "\n",
    "    image = tf.image.resize(image, img_size)\n",
    "    return image\n",
    "\n",
    "\n",
    "def preprocess_test_triplets(anchor_id, positive_id, negative_id):\n",
    "    '''\n",
    "    preprocessing_image was inspired by: https://keras.io/examples/vision/siamese_network/\n",
    "    Given the filenames corresponding to the three images, load and preprocess them.\n",
    "    '''\n",
    "    anchor = preprocess_test_image(create_path(anchor_id))\n",
    "    positive = preprocess_test_image(create_path(positive_id))\n",
    "    negative = preprocess_test_image(create_path(negative_id))\n",
    "\n",
    "    return tf.stack([anchor, positive, negative], axis = 0)\n",
    "\n",
    "\n",
    "def create_path(triplet_id):\n",
    "    '''\n",
    "    Needed to make it easier to load pictures\n",
    "    creates the path to the food folder for each line....\n",
    "    '''\n",
    "    return \"gdrive/MyDrive/food/\" + triplet_id + \".jpg\"\n",
    "\n",
    "\n",
    "def preprocess_triplets(anchor_id, positive_id, negative_id):\n",
    "    '''\n",
    "    loading the individual triplets.\n",
    "    Given the filenames corresponding to the three images, load and preprocess them.\n",
    "    '''\n",
    "    anchor = preprocess_image(create_path(anchor_id))\n",
    "    positive = preprocess_image(create_path(positive_id))\n",
    "    negative = preprocess_image(create_path(negative_id))\n",
    "\n",
    "    return tf.stack([anchor, positive, negative], axis = 0), 1\n",
    "\n",
    "\n",
    "def get_loss(pseudo_target, image_features):\n",
    "    anchor = image_features[..., 0]\n",
    "    positive = image_features[..., 1]\n",
    "    negative = image_features[..., 2] \n",
    "\n",
    "    ap_distance = tf.reduce_sum(tf.square(anchor - positive), 1)\n",
    "    an_distance = tf.reduce_sum(tf.square(anchor - negative), 1)\n",
    "    loss = tf.reduce_mean(tf.math.softplus(ap_distance - an_distance))\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def get_accuracy(pseudo_target, image_features):\n",
    "\n",
    "    anchor = image_features[..., 0]\n",
    "    positive = image_features[..., 1]\n",
    "    negative = image_features[..., 2] \n",
    "\n",
    "    ap_distance = tf.reduce_sum(tf.square(anchor - positive), 1)\n",
    "    an_distance = tf.reduce_sum(tf.square(anchor - negative), 1)\n",
    "    \n",
    "    acc = tf.reduce_mean(tf.cast(tf.greater_equal(an_distance, ap_distance), tf.float32))\n",
    "    return acc\n",
    "\n",
    "# MAIN CODE PART COMBINING EVERYTHING TOGETHER...\n",
    "# ---------------------------------------------------------------------------------------------------------------------------\n",
    "def main():\n",
    "    '''\n",
    "    importing and splitting the data into trainig and validation set. this can be expanedd to Cross Validation if \n",
    "    the trained model does not take too long to fit the data.\n",
    "    ''' \n",
    "    # -----------------------------------------------------------------------------------------------------------------------\n",
    "    n_train = 59515\n",
    "    n_batch = 64\n",
    "    n_epoch = 5\n",
    "    fine_tune_epochs = 1\n",
    "    n_buffer = 1024\n",
    "    base_learning_rate = 1e-3 # in order to have the relation steps_per_epoch * batch_size = number_of_rows_in_train_data\n",
    "    n_step_per_epoch =  np.ceil(n_train / n_batch)\n",
    "    finetuning = True\n",
    "    fine_tune_at = 135\n",
    "\n",
    "\n",
    "    # Creating the datapipeline for the model: Keras Models will iterate without creating a loop through all of the batches\n",
    "    # -----------------------------------------------------------------------------------------------------------------------\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE \n",
    "    trips_train = tf.data.TextLineDataset('gdrive/MyDrive/train_triplets.txt')\n",
    "    trips_train = trips_train.map(\n",
    "        lambda trip: preprocess_triplets(tf.strings.split(trip)[0],\n",
    "                                         tf.strings.split(trip)[1],\n",
    "                                         tf.strings.split(trip)[2]), num_parallel_calls = AUTOTUNE)\n",
    "\n",
    "    trips_test = tf.data.TextLineDataset('gdrive/MyDrive/test_triplets.txt')\n",
    "    trips_test = trips_test.map(\n",
    "        lambda trip: preprocess_test_triplets(tf.strings.split(trip)[0], \n",
    "                                              tf.strings.split(trip)[1], \n",
    "                                              tf.strings.split(trip)[2]), num_parallel_calls = AUTOTUNE)\n",
    "\n",
    "    trips_train = trips_train.shuffle(buffer_size = n_buffer, seed = 777,\n",
    "            reshuffle_each_iteration = True).repeat().batch(n_batch, drop_remainder = False)\n",
    "\n",
    "\n",
    "\n",
    "    # get the basemodel. also prepare it for fine tuning. \n",
    "    # -----------------------------------------------------------------------------------------------------------------------\n",
    "    base_cnn = tf.keras.applications.MobileNetV2(weights = 'imagenet', \n",
    "                                                 input_shape = img_shape, \n",
    "                                                 include_top = False)\n",
    "    base_cnn.trainable = False\n",
    "    in_shape = (3, ) + img_shape    \n",
    "    features_machine = tf.keras.Sequential([tf.keras.layers.GlobalAveragePooling2D(), \n",
    "        tf.keras.layers.Dense(128), \n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(128),\n",
    "        tf.keras.layers.Lambda(lambda b_norm: tf.math.l2_normalize(b_norm, axis=1))])\n",
    "    \n",
    "    # from inputs till output for model\n",
    "    inputs = tf.keras.Input(shape=in_shape)\n",
    "    base_cnn_anchor = base_cnn(inputs[:, 0, ...])\n",
    "    base_cnn_positive = base_cnn(inputs[:, 1, ...])\n",
    "    base_cnn_negative = base_cnn(inputs[:, 2, ...])\n",
    "    feature_mach_anchor = features_machine(base_cnn_anchor)\n",
    "    feature_mach_positive = features_machine(base_cnn_positive)\n",
    "    feautre_mach_negative = features_machine(base_cnn_negative)\n",
    "\n",
    "    outputs = tf.stack([feature_mach_anchor, feature_mach_positive, feautre_mach_negative], axis = -1)\n",
    "\n",
    "    features_model = Model(inputs = inputs, outputs = outputs)\n",
    "    features_model.summary()\n",
    "\n",
    "\n",
    "    # Modelfitting\n",
    "    # -----------------------------------------------------------------------------------------------------------------------\n",
    "    print(\"# -------------------------------------------- MODEL FITTING -------------------------------------------- #\")\n",
    "    features_model.compile(optimizer=optimizers.Adam(base_learning_rate), loss = get_loss, metrics = [get_accuracy])\n",
    "    history = features_model.fit(trips_train, \n",
    "                                 epochs = n_epoch, \n",
    "                                 steps_per_epoch = n_step_per_epoch)\n",
    "\n",
    "\n",
    "    # FineTuning\n",
    "    # -----------------------------------------------------------------------------------------------------------------------\n",
    "    print(\"# -------------------------------------------- FINE TUNING -------------------------------------------- #\")\n",
    "    if finetuning:\n",
    "        base_cnn.trainable = True\n",
    "        for layer in base_cnn.layers[:fine_tune_at]:\n",
    "            layer.trainable =  False\n",
    "\n",
    "        features_model.compile(loss=get_loss,\n",
    "                  optimizer = tf.keras.optimizers.RMSprop(base_learning_rate/10),\n",
    "                  metrics=[get_accuracy])\n",
    "        features_model.summary()\n",
    "        features_model.fit(trips_train, \n",
    "                           epochs = int(n_epoch + fine_tune_epochs),\n",
    "                           initial_epoch=history.epoch[-1],\n",
    "                           steps_per_epoch = n_step_per_epoch)\n",
    "\n",
    "\n",
    "    # Predicitions\n",
    "    # -----------------------------------------------------------------------------------------------------------------------\n",
    "    print(\"# -------------------------------------------- PREDICTING ITERATIONS -------------------------------------------- #\")\n",
    "    trips_test = trips_test.batch(256).prefetch(2)\n",
    "    predictions = []\n",
    "    i = 0\n",
    "\n",
    "    for x in trips_test:\n",
    "        sample = x\n",
    "        embeddings = features_model(sample)\n",
    "        anchor_test = embeddings[..., 0]\n",
    "        positive_test = embeddings[..., 1]\n",
    "        negative_test = embeddings[..., 2] \n",
    "\n",
    "        ap_distance_test = tf.reduce_sum(tf.square(anchor_test - positive_test), 1)\n",
    "        an_distance_test = tf.reduce_sum(tf.square(anchor_test - negative_test), 1)\n",
    "\n",
    "        predictions.append(tf.cast(tf.greater_equal(an_distance_test, ap_distance_test), tf.int8).numpy().tolist())\n",
    "        print(\"Predicition Iteration: {}\".format(i))\n",
    "        i = i + 1\n",
    "\n",
    "\n",
    "    predictions = pd.DataFrame(np.array(list(itertools.chain(*predictions))).reshape(-1, 1))\n",
    "    predictions.to_csv('gdrive/MyDrive/binary.csv', header = None, index = False)\n",
    "\n",
    "    # FINISH\n",
    "    # -----------------------------------------------------------------------------------------------------------------------\n",
    "    print(\"# -------------------------------------------- FINISHED AND SAVED -------------------------------------------- #\")\n",
    "                  \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DimM9S_OdURQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMXTixUf8zak5ehR3/at1+j",
   "collapsed_sections": [],
   "name": "task4Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
